{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from joblib import Memory\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize, FunctionTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import HDBSCAN\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "\n",
    "import preprocessing_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = './cache'\n",
    "memory = Memory(location=cache_dir, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10189, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('data/train.csv')\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3044, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name = ['Algebra', 'Geometry', 'Calculus', 'Statistics', 'Number_theory', 'Combinatorics', 'Linear_Algebra', 'Abstract_Algebra']\n",
    "# category_name = np.array(category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_val = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Training Data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(np.array(training_data['Question']), np.array(training_data['label']), \n",
    "                                                          random_state=0, stratify=training_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7641,) (7641,) \n",
      " (2548,) (2548,)\n"
     ]
    }
   ],
   "source": [
    "print(text_train.shape, y_train.shape,'\\n',text_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1 - Spacy's TextCategorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load blank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "textcat = nlp.add_pipe('textcat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding text categorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in category_name:\n",
    "    textcat.add_label(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to get training data in required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_spacy_fmt(text_array, y_array):\n",
    "    y_bin = label_binarize(y=y_array, classes=category_val)\n",
    "    result = []\n",
    "    for i, (ques, labels) in enumerate(zip(text_array, y_bin)):\n",
    "        label_dict = {}\n",
    "        label_dict.update({category_name[0]: int(labels[0]), category_name[1]: int(labels[1]),\n",
    "                           category_name[2]: int(labels[2]), category_name[3]: int(labels[3]),\n",
    "                           category_name[4]: int(labels[4]), category_name[5]: int(labels[5]),\n",
    "                           category_name[6]: int(labels[6]), category_name[7]: int(labels[7])})\n",
    "        # print((ques, {'cats': label_dict}))\n",
    "        result.append((ques, {'cats': label_dict}))\n",
    "    return result\n",
    "    # print(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_spacy = get_data_spacy_fmt(text_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Example objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for text, ann in text_train_spacy:\n",
    "    doc = nlp.make_doc(text)\n",
    "    examples.append(Example.from_dict(doc, ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.optimizers.Optimizer at 0x7fcc2a997600>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.initialize(lambda: examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Losses: {'textcat': 14.926491281017661}\n",
      "Epoch 1 Losses: {'textcat': 8.25029822718352}\n",
      "Epoch 2 Losses: {'textcat': 4.864947982830927}\n",
      "Epoch 3 Losses: {'textcat': 2.6307922412233893}\n",
      "Epoch 4 Losses: {'textcat': 1.7937833745272656}\n",
      "Epoch 5 Losses: {'textcat': 1.2696381553037526}\n",
      "Epoch 6 Losses: {'textcat': 0.9274789209684684}\n",
      "Epoch 7 Losses: {'textcat': 0.8745670416837399}\n",
      "Epoch 8 Losses: {'textcat': 0.7566490123098468}\n",
      "Epoch 9 Losses: {'textcat': 0.6602426764256863}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    random.shuffle(examples)\n",
    "    losses = {}\n",
    "    batches = minibatch(examples, size=compounding(4, 32, 1.5))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, losses=losses)\n",
    "    print(f'Epoch {epoch} Losses:', losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk('nlp_model/math_textcat_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_nlp = spacy.load('nlp_model/math_textcat_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = []\n",
    "for ques in text_test:\n",
    "    doc = math_nlp(ques)\n",
    "    pred_label = max(doc.cats, key=doc.cats.get)\n",
    "    pred_val.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algebra': 0,\n",
       " 'Geometry': 1,\n",
       " 'Calculus': 2,\n",
       " 'Statistics': 3,\n",
       " 'Number_theory': 4,\n",
       " 'Combinatorics': 5,\n",
       " 'Linear_Algebra': 6,\n",
       " 'Abstract_Algebra': 7}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {}\n",
    "for label, name in enumerate(category_name):\n",
    "    label_map.update({name: label})\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({\n",
    "    'Question' : text_test,\n",
    "    'Pred_label' : pred_val\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['pred_value'] = val_df['Pred_label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro score using Spacy Model on Validation set: 0.763\n"
     ]
    }
   ],
   "source": [
    "math_nlp_score = f1_score(y_pred=val_df['pred_value'], y_true=y_test, average='micro')\n",
    "print(f'f1-micro score using Spacy Model on Validation set: {math_nlp_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_pred=val_df['pred_value'], y_true=y_test))\n",
    "# ConfusionMatrixDisplay.from_predictions(y_test, val_df['pred_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m spacy train ./math_nlp_2/config.cfg \\\n",
    "  --training.train_corpus ./data/train.spacy \\\n",
    "  --training.dev_corpus ./data/dev.spacy \\\n",
    "  --output ./math_nlp_2/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
